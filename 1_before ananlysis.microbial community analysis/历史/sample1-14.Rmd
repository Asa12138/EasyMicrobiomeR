---
title: "Using R in microbial analysis"
author: "Tao Wen(文涛)"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    theme: cerulean
    highlight: haddock
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: yes
    code_fold: show
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = T, echo=T, comment="#>", message=F, warning=F,
	fig.align="center", fig.width=7, fig.height=5, dpi=150)
```


# Title


## Introduction



## Before microbiome data analysis


### Microbial community data preparation

### visualization in R language




## microbial community analysis


### microbial community diversity analysis


### microbial community difference analysis


### Micrboial biomarker judgment


### Correction and network analysis


### Functional predict


### Other microbial analysis


## Microbial data analysis integrated

see single `.Rmd` file



```{R}
# ?read.delim
# ?read.table
# ?read.csv
library(ape)
# ?read.tree
library(ggtree)
# ?read.tree
library(phyloseq)
# ?read_tree
library(Biostrings)
# ?readDNAStringSet
```


#--示例一：基础包对微生物组数据处理#-----

```{R}
otu = read.delim("./data/otutab.txt",header = T,row.names = 1)
head(otu)

#--循环+sum统计测序深度
A= c()
for (i in 1:dim(otu)[2]) {
  B = sum(otu[,i])
  A = c(A,B)
}
names(A) = colnames(otu)
A#--可使用函数colSums(otu)替代

#-计算物种相对丰度
otu2 = as.matrix(otu)
norm = otu2/A

#使用base中的apply家族函数
apply(otu,2,sum)
```


#--示例二：plyr包处理微生物组数据#-----------

```{R}
otu = read.delim("./data/otutab.txt",header = T,row.names = 1)
tax = read.delim("./data/taxonomy.txt",header = T,row.names = 1)
dat = cbind(otu,tax)

library(plyr)
#-指定列计算
ddply(dat,.(Phylum),summarize,meanWT1 = mean(WT1))
#-应用于每一列
ddply(dat,.(Phylum),colwise(mean))
```


#--示例三 reshape2数据融合#-----------

```{R}
library(reshape2)
otu = read.delim("./data/otutab.txt",header = T,row.names = 1)
head(otu)
otu$ID = row.names(otu)
dat <- melt(otu)
head(dat)
```


#--示例四 dplyr数据处理#--------

```{R}
library(tidyverse)
otu = read.delim("./data/otutab.txt",header = T,row.names = 1)
tax = read.delim("./data/taxonomy.txt",header = T,row.names = 1)
map= read.delim("./data/metadata.tsv",row.names = 1) 
map$ID = row.names(map)
head(map)
colnames(map)[6] = "Spe"

otu2 = t(as.matrix(otu)) %>% as.data.frame()
otu2$ID = row.names(otu2)
tax$taxid = row.names(tax)
head(tax)

data = map %>% as.tibble() %>%
  inner_join(otu2,by=  "ID") %>% 
  gather( taxa, count, starts_with("ASV_")) %>%
  inner_join(tax,by = c("taxa" = "taxid") )
data
```

#---随机森林建模

```{R}
library(randomForest)
get_importance <- function(x){
  rf <- randomForest(x[,3:ncol(x)], as.factor(x$Group), importance = T)
  imps <- as.data.frame(rf$importance)
  imps$variable <- row.names(imps)
  # names(imps)[1] <- "PercIncMSE"
  as_tibble(imps)
}

imps <- data %>% 
  # filter(Compartment != "Bulk Soil" & Compartment != "Rhizoplane") %>% 
  dplyr::select(Group,count, taxa, ID) %>% 
  spread(taxa, count, fill = 0) %>% # 列表转化为数据，空白的地方填充0
  nest() %>% 
  mutate(imp = map(data, ~ get_importance(.)))

top_otus <- imps %>% 
  unnest(imp) %>% # tibble钟折叠的imp数据框展开分析
  # group_by(Compartment, Site) %>% 
  top_n(85, MeanDecreaseAccuracy) # 提取每个模型前85个个重要OTU
```


#---示例五alpha多样性#-------

```{R}
library(vegan)
otu = read.delim("./data/otutab.txt",header = T,row.names = 1)
tree = read_tree("./data/otus.tree")
head(otu)
otu2 = as.data.frame(t(rrarefy(t(otu),min(colSums(otu)))))
colSums(otu2)
otul = decostand(t(otu),'log') %>% t()


otu.alp = t(otu2)
# Richness 
observed_species <- estimateR(otu.alp)[1, ]
# Chao 1
Chao1  <- estimateR(otu.alp)[2, ]
Chao1
# ACE 
ACE  <- estimateR(otu.alp)[4, ]
ACE
# Shannon
Shannon <- diversity(otu.alp, index = 'shannon', base = exp(1))#以e作为底数表示方法
Shannon <- diversity(otu.alp, index = 'shannon', base = 2) #以2作为底数表示方法
Shannon
# Simpson1
Gini_simpson  <- diversity(otu.alp, index = 'simpson')
Gini_simpson
#Simpson2
simpson_index <- 1 - Gini_simpson
# goods_coverage 
goods_coverage <- 1 - rowSums(otu.alp == 1) / rowSums(otu.alp)
goods_coverage

# PD
library(picante) 
library(ape)
?pd
PD_whole_tree <- pd(otu, tree, include.root = FALSE)[1]
PD_whole_tree
```


#---示例六排序分析#-------

```{R}
library(vegan)
library(MASS)
otu = read.delim("./data/otutab.txt",header = T,row.names = 1)
env = read.delim("./data/env.txt",header = T,row.names = 1)
head(otu)

# RDA
RDA <- rda(t(otu),env,scale = T)

# DCA
DCA<- decorana(otu)

# CCA
CCA <- cca(t(otu),env,scale = T)

# NMDS
dist <-vegdist(t(otu),method = "bray")
nmds_dist <- metaMDS(dist,k =2)


# PCA
PCA <- prcomp(t(otu), center = T,scale = T)

# MCA
install.packages("FactoMineR")
library(FactoMineR)
data(tea)

RES.MCA <- MCA(t(otu), graph = F,ncp = 5 )
?mca

# PCOA
dist= vegdist(t(otu),method = "bray")
PCOA= pcoa(dist,correction = "cailliez")

# LDA
data = t(otu)
# head(data)
data = as.data.frame(data)
# data$ID = row.names(data)
data = scale(data, center = TRUE, scale = TRUE)
model = MASS::lda(data, map$Group)

# VEGDIST
Vegan.dist = vegdist(t(otu),method = "bray")

# DIST
library(stats)
DIST<- dist(t(otu),method = "euclidean")
```


#--示例七：聚类分析#--------

```{R}
# HCLUST
dist<- dist(t(otu),method = "euclidean" )
otu.hclust <- hclust(dist, method = "complete")

# CLUSTER
library(survival)
CLUSTER<- cluster(t(otu))

# KMEANS
library(factoextra)
library(cluster)

scale(t(otu))
set.seed(1)

gap = clusGap(scale(t(otu)),FUN = kmeans,nstart = 25,K.max = 10,B = 500)
fviz_gap_stat(gap)
KM<- kmeans(scale(t(otu)),centers =3 , nstart = 25)
```


#--示例八：群落整体差异分析#---------

```{R}
library(vegan)
library(tidyverse)
library(ade4)

otu = read.delim("./data/otutab.txt",header = T,row.names = 1)
map= read.delim("./data/metadata.tsv",row.names = 1) 

unif <- dist <-vegdist(t(otu),method = "bray")
# ADONIS
ado = vegan:: adonis2( unif~ map$Group,method = "bray", by = NULL)
ado
# ANOSIM
dat.ano = vegan::anosim(unif, map$Group)
dat.ano
# MRPP
mrpp = vegan::mrpp(unif, map$Group)
mrpp
# MANTEL

dist <- 
  otu %>% t() %>%
  vegan::vegdist(method="bray") %>%
  as.matrix()
gru = map[,"Group"][,1] %>% unlist() %>% as.vector()
id = combn(unique(gru),2)
i = 1
id_dist <- row.names(map)[gru == id[1,i]]
dist1 = dist[id_dist,id_dist]
id_dist <- row.names(map)[gru == id[2,i]]
id_dist = id_dist[1:nrow(dist1)]
dist2 = dist[id_dist,id_dist]
vegan::mantel(dist1,dist2,method = "spearman")
```


#--示例九：差异分析#--------

```{R}
# devtools::install_github("taowenmicro/ggClsuterNet")
library(ggClusterNet)
library(phyloseq)
#---wilcox.test
map= sample_data(ps)
head(map)
id.g = map$Group %>% unique() %>% as.character() %>% combn(2)

ASV_table = ps %>% 
  scale_micro(method = "sampling") %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group %in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)

pvals <- apply(ASV_table, 1, function(x) wilcox.test(x ~ groupings$Group, exact=F)$p.value)
dat <- pvals %>% as.data.frame()
head(dat)
colnames(dat) = "p"
tab.d12 = dat %>% 
  rownames_to_column(var = "id") %>%
  dplyr::select(id,p) %>%
  dplyr::filter( p < 0.05) %>% 
  dplyr::rename(
    OTU = id
    # p = p
  )  %>% 
  dplyr::mutate(group = " wilcox.test.rare")

head(tab.d12)
```

#---t.test

```{R}
map= sample_data(ps)
head(map)
id.g = map$Group %>% unique() %>% as.character() %>% combn(2)

ASV_table = ps %>% 
  scale_micro(method = "sampling") %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group %in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)

pvals <- apply(ASV_table, 1, function(x) t.test(x ~ groupings$Group, exact=F)$p.value)

dat <- pvals %>% as.data.frame()
head(dat)
colnames(dat) = "p"

tab.d11 = dat %>% 
  rownames_to_column(var = "id") %>%
  dplyr::select(id,p) %>%
  dplyr::filter( p < 0.05) %>% 
  dplyr::rename(
    OTU = id
    # p = p
  )  %>% 
  dplyr::mutate(group = "t.test.rare")
head(tab.d11)
```

#-edgeR

```{R}
library(edgeR)

phyloseq_to_edgeR = function(physeq, group, method="RLE", ...){
  require("edgeR")
  require("phyloseq")
  # Enforce orientation.
  if( !taxa_are_rows(physeq) ){ physeq <- t(physeq) }
  x = as(otu_table(physeq), "matrix")
  # Add one to protect against overflow, log(0) issues.
  x = x + 1
  # Check `group` argument
  if( identical(all.equal(length(group), 1), TRUE) & nsamples(physeq) > 1 ){
    # Assume that group was a sample variable name (must be categorical)
    group = get_variable(physeq, group)
  }
  # Define gene annotations (`genes`) as tax_table
  taxonomy = tax_table(physeq, errorIfNULL=FALSE)
  if( !is.null(taxonomy) ){
    taxonomy = data.frame(as(taxonomy, "matrix"))
  } 
  # Now turn into a DGEList
  y = DGEList(counts=x, group=group, genes=taxonomy, remove.zeros = TRUE, ...)
  # Calculate the normalization factors
  z = calcNormFactors(y, method=method)
  # Check for division by zero inside `calcNormFactors`
  if( !all(is.finite(z$samples$norm.factors)) ){
    stop("Something wrong with edgeR::calcNormFactors on this data,
         non-finite $norm.factors, consider changing `method` argument")
  }
  # Estimate dispersions
  return(estimateTagwiseDisp(estimateCommonDisp(z)))
}

phylo <- ps %>%
  subset_samples(Group %in% id.g[,i])

test <- phyloseq_to_edgeR(physeq = phylo, group="Group")

et = exactTest(test)

tt = topTags(et, n=nrow(test$table), adjust.method="fdr", sort.by="PValue")
res <- tt@.Data[[1]]
head(res)
tab.d4 = res %>% 
  rownames_to_column(var = "id") %>%
  dplyr::select(id,FDR) %>%
  dplyr::filter(FDR < 0.05) %>% 
  dplyr::rename(
    OTU = id,
    p = FDR
  )  %>% 
  dplyr::mutate(group = "edgeR")

head(tab.d4)
```

# DESeq2

```{R}

library(DESeq2)
ASV_table = ps %>% 
  filter_taxa(function(x) sum(x ) > 0 , TRUE) %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group%in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)
dds <- DESeq2::DESeqDataSetFromMatrix(countData = ASV_table,
                                      colData=groupings,
                                      design = ~ Group)
dds_res <- DESeq2::DESeq(dds, sfType = "poscounts")

res <- DESeq2::results(dds_res, tidy=T, format="DataFrame")

rownames(res) <- res$row
res <- res[,-1]
head(res)
tab.d5 = res %>% 
  rownames_to_column(var = "id") %>%
  dplyr::select(id,padj) %>%
  dplyr::filter(padj < 0.05) %>% 
  dplyr::rename(
    OTU = id,
    p = padj
  )  %>% 
  dplyr::mutate(group = "DESeq2")

head(tab.d5)
```

#--metagennomeSeq

```{R}
library(metagenomeSeq)
ASV_table = ps %>% 
  filter_taxa(function(x) sum(x ) > 0 , TRUE) %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group%in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)

data_list <- list()
data_list[["counts"]] <- ASV_table
data_list[["taxa"]] <- rownames(ASV_table)

pheno <- AnnotatedDataFrame(groupings)
pheno
counts <- AnnotatedDataFrame(ASV_table)
feature_data <- data.frame("ASV"=rownames(ASV_table),
                           "ASV2"=rownames(ASV_table))
feature_data <- AnnotatedDataFrame(feature_data)
rownames(feature_data) <- feature_data@data$ASV


test_obj <- newMRexperiment(counts = data_list$counts, phenoData = pheno, featureData = feature_data)

p <- cumNormStat(test_obj, pFlag = T)


test_obj_norm <- cumNorm(test_obj, p=p)

fromula <- as.formula(paste(~1, "Group", sep=" + "))
pd <- pData(test_obj_norm)
mod <- model.matrix(fromula, data=pd)
regres <- fitFeatureModel(test_obj_norm, mod)

res_table <- MRfulltable(regres, number = length(rownames(ASV_table)))
head(res_table)

tab.d10 = res_table %>% 
  rownames_to_column(var = "id") %>%
  dplyr::select(id,adjPvalues) %>%
  dplyr::filter(adjPvalues < 0.05) %>% 
  dplyr::rename(
    OTU = id,
    p = adjPvalues
  )  %>% 
  dplyr::mutate(group = "metagenomeSeq")

head(tab.d10)
```

# ALDEx2

```{R}
library(ALDEx2)
ASV_table = ps %>% 
  filter_taxa(function(x) sum(x ) > 0 , TRUE) %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group%in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)
#mc.samples:一个整数。 估计基础分布时使用的蒙特卡洛样本数
results <- aldex(reads=ASV_table, conditions = groupings$Group,
                 mc.samples = 128,
                 test="t", 
                 effect=TRUE,
                 include.sample.summary = FALSE, 
                 verbose=T, 
                 denom="all")

head(results)
#使用Welchs t 检验矫正后的p值 作为显著差异的微生物
tab.d1 = results %>% 
  as.data.frame() %>%
  dplyr::filter(we.ep < 0.05) %>% rownames_to_column(var = "id") %>%
  dplyr::select(id,we.ep) %>%
  dplyr::rename(
    OTU = id,
    p = we.ep
  ) %>% 
  dplyr::mutate(group = "Aldex2")

head(tab.d1)
```

#--limma

```{R}
ASV_table = ps %>% 
  filter_taxa(function(x) sum(x ) > 0 , TRUE) %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group%in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)
DGE_LIST <- DGEList(ASV_table)
### do normalization
### Reference sample will be the sample with the highest read depth
### check if upper quartile method works for selecting reference
Upper_Quartile_norm_test <- calcNormFactors(DGE_LIST, method="upperquartile")
summary_upper_quartile <- summary(Upper_Quartile_norm_test$samples$norm.factors)[3]
if(is.na(summary_upper_quartile) | is.infinite(summary_upper_quartile)){
  message("Upper Quartile reference selection failed will use find sample with largest sqrt(read_depth) to use as reference")
  Ref_col <- which.max(colSums(sqrt(ASV_table)))
  DGE_LIST_Norm <- calcNormFactors(DGE_LIST, method = "TMM", refColumn = Ref_col)
  fileConn<-file(args[[4]])
  writeLines(c("Used max square root read depth to determine reference sample"), fileConn)
  close(fileConn)
  
}else{
  DGE_LIST_Norm <- calcNormFactors(DGE_LIST, method="TMM")
}

## make matrix for testing
# colnames(groupings) <- c("comparison")
groupings = groupings %>% as.tibble() %>% as.data.frame()
mm <- model.matrix(~Group, groupings)

voomvoom <- voom(DGE_LIST_Norm, mm, plot=F)

fit <- lmFit(voomvoom,mm)
fit <- eBayes(fit)
res <- topTable(fit, coef=2, n=nrow(DGE_LIST_Norm), sort.by="none")
head(res)

tab.d7 = res %>% 
  rownames_to_column(var = "id") %>%
  dplyr::select(id,adj.P.Val) %>%
  dplyr::filter(adj.P.Val < 0.05) %>% 
  dplyr::rename(
    OTU = id,
    p = adj.P.Val
  )  %>% 
  dplyr::mutate(group = "limma.voom.TMM")

head(tab.d7)
```

#--ANCOM-II

```{R}

#-第二种：ANCOM-II#-------------
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\ancom_v2.1.R")
ASV_table = ps %>% 
  filter_taxa(function(x) sum(x ) > 200 , TRUE) %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group%in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)
groupings$Sample <- rownames(groupings)
prepro <- feature_table_pre_process(feature_table = ASV_table, meta_data = groupings, sample_var = 'Sample', 
                                    group_var = NULL, out_cut = 0.05, zero_cut = 0.90,
                                    lib_cut = 1000, neg_lb=FALSE)

feature_table <- prepro$feature_table
metadata <- prepro$meta_data
struc_zero <- prepro$structure_zeros
```

#--run ancom

```{R}
main_var <- colnames(groupings)[1]
p_adj_method = "BH"
alpha=0.05
adj_formula=NULL
rand_formula=NULL
res <- ANCOM(feature_table = feature_table, 
             meta_data = metadata,
             struc_zero = struc_zero, 
             main_var = main_var,
             p_adj_method = p_adj_method,
             alpha=alpha, adj_formula = adj_formula, 
             rand_formula = rand_formula
)

dat = res$out
head(dat)
dat$detected_0.6
ANCOM.value = "detected_0.6"
tab.d2 = dat %>% dplyr::select(taxa_id,detected_0.6) %>%
  dplyr::filter(detected_0.6 == TRUE) %>% 
  dplyr::rename(
    OTU = taxa_id,
    p = detected_0.6
  )  %>% 
  dplyr::mutate(group = "ANCOMII")

# 不同阈值的显著差异的数量不同，随着阈值越来越大，显著的OTU也越来越少
# write.table(res$out, file= "./ANCOM.txt", quote=FALSE, sep="\t", col.names = NA)
```

#--corcob

```{R}
library(corncob)
phylo <- ps %>%
  subset_samples(Group %in% id.g[,i])

my_formula <- as.formula(paste("~","Group",sep=" ", collapse = ""))
my_formula
results <- corncob::differentialTest(formula= my_formula,
                                     phi.formula = my_formula,
                                     phi.formula_null = my_formula,
                                     formula_null = ~ 1,
                                     test="Wald", data=phylo,
                                     boot=F,
                                     fdr_cutoff = 0.05)
dat = results$p_fdr  %>% as.data.frame()
head(dat)
colnames(dat) = "p_fdr"
dat$p = results$p

tab.d3 = dat %>% 
  rownames_to_column(var = "id") %>%
  dplyr::select(id,p_fdr) %>%
  dplyr::filter(p_fdr < 0.05) %>% 
  dplyr::rename(
    OTU = id,
    p = p_fdr
  )  %>% 
  dplyr::mutate(group = "corncob")

head(tab.d3)
```

#Maaslin2

```{R}
ASV_table = ps %>% 
  filter_taxa(function(x) sum(x ) > 0 , TRUE) %>%
  subset_samples(Group %in% id.g[,i]) %>%
  vegan_otu() %>% t() %>%
  as.data.frame()
groupings <- ps %>%
  subset_samples(Group%in% id.g[,i]) %>%
  sample_data()
groupings$ID = row.names(groupings)
library(Maaslin2)
# 会生成一个文件夹
# 一个稀释后的或未经稀释的特征表
# 反正弦平方根变换(arcsine square-root transformation)。
# 没有指定随机效应，并关闭了默认的标准化。该函数将线性模型拟合到指定样本分组上每个特征的转换丰度，
# 使用Wald检验进行显著性检验，并输出BH FDR校正的p值
ASV_table <- data.frame(t(ASV_table), check.rows = F, check.names = F, stringsAsFactors = F)

row.names(groupings) = groupings$ID

fit_data <- Maaslin2(
  ASV_table, groupings,"Maaslin2", transform = "AST",
  fixed_effects = "Group",
  standardize = FALSE, plot_heatmap = F, plot_scatter = F)

dat = fit_data$results
head(dat)
tab.d9 = dat %>% 
  # rownames_to_column(var = "id") %>%
  dplyr::select(feature,qval) %>%
  dplyr::filter(qval < 0.05) %>% 
  dplyr::rename(
    OTU = feature,
    p = qval
  )  %>% 
  dplyr::mutate(group = "Maaslin2")
head(tab.d9)

write.table(dat, file="Maaslin2.txt", quote=F, sep="\t", col.names = NA)
```


#---示例十：寻找生物标志物#------

```{R}
# LeFSe 
source("E:/Shared_Folder/Function_local/R_function/micro/R_lefse_SAV.R",encoding = "utf-8")

p1 <- p_base(ps,Top = 100)
p1$data
mytheme1 = theme_bw()
tablda = LDA_Micro(ps = ps,
                   Top = 100,
                   p.lvl = 0.05,
                   lda.lvl = 1,
                   seed = 11, 
                   adjust.p = F)

p <- lefse_bar(taxtree = tablda[[2]])
tem = tablda[[2]]
head(tem)
```

#--PCA 载荷矩阵

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro/loadingPCA.R")
res = loadingPCA(ps = ps %>% filter_OTU_ps(200),Top = 20)
p = res[[1]]
p
dat = res[[2]]
head(dat )
```

#--随机森林

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\MicroMachine_learning.R")

mapping = as.data.frame(phyloseq::sample_data(ps))
#--随机森林全套-如果圈图尚未显示前面几个，就设定max大一点
result = MicroRF(ps = ps %>% filter_OTU_ps(500),
                 group  = "Group",
                 optimal = 20,rfcv = F,nrfcvnum = 5,
                 min = -1,max = 5)
#火柴图展示前二十个重要的OTU
p <- result[[1]]
p

# 抽空补充mboost等其他机器学习
```

#--ROC曲线
#--三种机器学习方法评测

```{R}
data(ps)
ps.1 = subset_samples.wt(ps,"Group",c("WT"),T) %>%
  filter_OTU_ps(500)
library(randomForest)
library(caret)
library(ROCR) ##用于计算ROC
library(e1071)
result = MicroRoc( ps = ps.1,group  = "Group")
#--提取roc曲线
p <- result[[1]] + 
  mytheme1
p
```


#示例十一：网络分析#-------

```{R}
library(psych)
ps_sub = filter_OTU_ps(ps = ps,Top = 150)
otu_table = as.data.frame(t(vegan_otu(ps_sub)))
head(otu_table)
occor = psych::corr.test(t(otu_table),use="pairwise",
                         adjust="fdr",alpha=.05)
occor.r = occor$r
occor.p = occor$p

result <- sparcc.micro(data = t(otu_table),R = R,ncpus = ncpus)
occor.r = result[[1]]
occor.p = result[[2]]
```

#----WGCNA

```{R}
x = ps %>%
  filter_OTU_ps(Top = 200) %>%
  # scale_micro(method = "TMM") %>%
  vegan_otu() %>%
  t() %>%
  as.data.frame()
occor<-WGCNA::corAndPvalue(t(x)/colSums(x))
mtadj<-multtest::mt.rawp2adjp(unlist(occor$p),proc='BH')
adpcor<-mtadj$adjp[order(mtadj$index),2]
occor.p<-matrix(adpcor,dim(t(x)/colSums(x))[2])
## R value
occor.r<-occor$cor
diag(occor.r) <- 0
```

#---Hmisc 

```{R}
library(Hmisc)
df_corr <- rcorr(t(otu_table), type = 'spearman')
df_corr_r = df_corr$r
df_corr_p = df_corr$P#注意，这里P大写
# 使用BH法校正p值
df_p <- p.adjust(df_corr_p, method = 'BH')
```

#-igraph

```{R}
library(Hmisc)
library(igraph)
library(ggClusterNet)
df_corr <- rcorr(t(otu_table), type = 'spearman')
df_corr_r = df_corr$r


igraph = make_igraph(df_corr_r)

num.edges <- length(E(igraph)) # length(curve_multiple(igraph))
num.edges
#  Order (number of vertices) of a graph
num.vertices <- length(V(igraph))# length(diversity(igraph, weights = NULL, vids = 	V(igraph)))
num.vertices
#
connectance <- edge_density(igraph,loops=FALSE)# 同 graph.density;loops如果为TRUE,允许自身环（self loops即A--A或B--B）的存在
connectance
# (Average degree)
average.degree <- mean(igraph::degree(igraph))# 或者为2M/N,其中M 和N 分别表示网络的边数和节点数。
average.degree
# (Average path length)
if (!is.null(E(igraph)$weight)) {
  igraph.weight <- E(igraph)$weight
  E(igraph)$weight = abs(E(igraph)$weight)
}
average.path.length <- average.path.length(igraph) # 同mean_distance(igraph) # mean_distance calculates the average path length in a graph
average.path.length

# (Diameter)
diameter <- diameter(igraph, directed = FALSE, unconnected = TRUE, weights = NULL)
diameter
```

#-SpiecEasi

```{R}
library(SpiecEasi)
spmatrix <- SpiecEasi::sparcc(t(otu_table))
tp0 <- proc.time()
sp.boot <- SpiecEasi::sparccboot(
  t(otu_table),
  R = 10,
  ncpus = 1
)
tp1 <- proc.time()
tp1 - tp0
sp.p <- SpiecEasi::pval.sparccboot(sp.boot, sided = "both")
cors <- sp.p$cors
sp.p$pvals[is.na(sp.p$pvals)] = 1
pvals <- sp.p$pvals
sparCCpcors <- diag(0.5, nrow = dim(spmatrix$Cor)[1], ncol = dim(spmatrix$Cor)[1])
sparCCpcors[upper.tri(sparCCpcors, diag=FALSE)] <- cors
sparCCpcors <- sparCCpcors + t(sparCCpcors)

sparCCpval <- diag(0.5, nrow = dim(spmatrix$Cor)[1], ncol = dim(spmatrix$Cor)[1])
sparCCpval[upper.tri(sparCCpval, diag=FALSE)] <- pvals
sparCCpval <- sparCCpval + t(sparCCpval)
dim(sparCCpval)

rownames(sparCCpcors) <- colnames(t(otu_table))
colnames(sparCCpcors) <- colnames(t(otu_table))
rownames(sparCCpval) <- colnames(t(otu_table))
colnames(sparCCpval) <- colnames(t(otu_table))
```

#--ggraph

```{R}
library(Hmisc)
df_corr <- rcorr(t(otu_table), type = 'spearman')
df_corr_r = df_corr$r
df_corr_p = df_corr$P#注意，这里P大写
# 使用BH法校正p值
df_p <- p.adjust(df_corr_p, method = 'BH')
df_corr_r[df_corr_p>0.05|abs(df_corr_r)<0.6] = 0
igraph = make_igraph(df_corr_r)

p  = ggraph(igraph) + 
  geom_edge_link(color = "blue") + 
  geom_node_point(color = "red") +
  theme_void()

p
```

#-igraph可视化

```{R}
set.seed(12)
plot(igraph,main="Co-occurrence network",
     vertex.frame.color=NA,
     edge.lty=1,
     edge.curved=TRUE,
     vertex.size=3,
     pch = 21,
     margin=c(0,0,0,0),
     vertex.label.cex=.1,
     vertex.label.dist=0.1,#标签大小
     layout=layout_in_circle#控制样式，具体见官方文档
)
```

#--sna 提供了多种网络可视化布局

# ggClsuterNet提供了多种网络可视化布局

```{R}
result = corMicro (ps = ps,
                   N = 150,
                   method.scale = "TMM",
                   r.threshold=0.8,
                   p.threshold=0.05,
                   method = "spearman"
                   
                   
)
cor = result[[1]]
ps_net = result[[3]]
otu_table = ps_net %>% 
  vegan_otu() %>%
  t() %>%
  as.data.frame()
tax_table = ps_net %>%
  vegan_tax() %>%
  as.data.frame()
netClu = data.frame(ID = row.names(tax_table),group =rep(1,length(row.names(tax_table)))[1:length(row.names(tax_table))] )
netClu$group = as.factor(netClu$group)
result2 = PolygonClusterG (cor = cor,nodeGroup =netClu )
node = result2[[1]]
nodes = nodeadd(plotcord =node,otu_table = otu_table,tax_table = tax_table)
edge = edgeBuild(cor = cor,node = node)
pnet <- ggplot() + geom_segment(aes(x = X1, y = Y1, xend = X2, yend = Y2,color = as.factor(cor)),
                                data = edge, size = 0.5) +
  geom_point(aes(X1, X2,fill = Phylum,size = mean),pch = 21, data = nodes) +
  scale_colour_brewer(palette = "Set1") +
  scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) +
  # labs( title = paste(layout,"network",sep = "_"))+
  # geom_text_repel(aes(X1, X2,label=Phylum),size=4, data = plotcord)+
  # discard default grid + titles in ggplot2
  theme(panel.background = element_blank()) +
  # theme(legend.position = "none") +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +
  theme(legend.background = element_rect(colour = NA)) +
  theme(panel.background = element_rect(fill = "white",  colour = NA)) +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank())
pnet
```

```{R}
dat = net_properties.2(igraph,n.hub = T)
head(dat,n = 16)
nodepro = node_properties(igraph)
head(nodepro)

result = random_Net_compate(igraph = igraph, type = "gnm", step = 100, netName = layout)
p1 = result[[1]]
sum_net = result[[4]]
p1
```

#--微生物网络一体化分析

```{R}
# data("ps16s")
# path = "./result_micro_200/"
# dir.create(path)
# result = network(ps = ps16s,
#                  N = 200,
#                  layout_net = "model_Gephi.2",
#                  r.threshold=0.6,
#                  p.threshold=0.05,
#                  label = FALSE,
#                  path = path,
#                  zipi = TRUE)
# # 多组网络绘制到一个面板
# p = result[[1]]
# p
# # 全部样本网络参数比对
# data = result[[2]]
# plotname1 = paste(path,"/network_all.jpg",sep = "")
# ggsave(plotname1, p,width = 48,height = 16,dpi = 72)
# plotname1 = paste(path,"/network_all.pdf",sep = "")
# ggsave(plotname1, p,width = 48,height = 16)
# tablename <- paste(path,"/co-occurrence_Grobel_net",".csv",sep = "")
# write.csv(data,tablename)
```


#--示例十二：其他微生物组分析#--------

```{R}
#--中性模型
library(picante)
library(ape)
library(vegan)
library(FSA)
library(eulerr)
library(grid)
library(gridExtra)
require(minpack.lm)
require(Hmisc)
require(stats4)
library(parallel)
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\phylo_Micro\\neutralModel.R")
result = neutralModel(ps = ps,group  = "Group",ncol = 3)
p1 =  result[[1]]
p1

#---计算零模型
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\phylo_Micro\\nullModel1.R")
result <- nullModel(ps = ps,
                    group="Group",
                    dist.method =  "bray",
                    gamma.method = "total",
                    transfer = "none",
                    null.model = "ecosphere"
)
#--分组零模型运行结果
nullModeltab <- result[[1]]
# 比例
ratiotab <- result[[2]]
#-统计量统计差异
aovtab <- result[[3]]
```

#--BNTI

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\phylo_Micro\\bNTICul.R")
result = bNTICul(ps = ps %>% filter_OTU_ps(200),group  = "Group",num = 10,thread = 1)
bNTI = result[[1]]
head(bNTI)

phypath = "./"
filename = paste(phypath,"/4_bNTI.csv",sep = "")
write.csv(bNTI, filename)
```

#--计算RCbray

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\phylo_Micro\\RCbary.R")
result = RCbary(ps = ps%>% filter_OTU_ps(200) ,group  = "Group",num = 10,thread = 1)
RCbary = result[[1]]
head(RCbary)
filename = paste(phypath,"/5_RCb.csv",sep = "")
write.csv(RCbary,filename)
```

#--BetaNTI和RCbray联合

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\phylo_Micro\\bNTIRCPlot.R")
bNTI = read.csv(paste(phypath,"/4_bNTI.csv",sep = ""),row.names = 1)
head(bNTI)
RCb = read.csv(paste(phypath,"/5_RCb.csv",sep = ""),row.names = 1) %>%
  dplyr::mutate(Sample_1 = Site2, Sample_2 = Site1)
head(RCb)
result = bNTIRCPlot(ps = ps %>% filter_OTU_ps(200) ,RCb  = RCb,bNTI = bNTI,group  = "Group")
#--bNTI出图片
p3 <- result[[1]] 
#RCbary可视化
p4 <- result[[2]] 
p4
#组合图片BNTI，RCbray
p5 <- result[[3]]
p5
plotdata = result[[4]]
head(plotdata)
dat = result[[5]]
head(dat)
filename = paste(phypath,"/6_bNTI_RCbray.csv",sep = "")
write.csv(plotdata,filename)
```

#---环境因子和BetaNTI相关

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\phylo_Micro\\EnvCorbNTI.R")
bNTIRC = read.csv(paste(phypath,"/6_bNTI_RCbray.csv",sep = ""),row.names = 1)
head(bNTIRC)

map = sample_data(ps %>% filter_OTU_ps(200) )
head(map)
data(env1)
plot = EnvCorbNTI(ps = ps %>% filter_OTU_ps(200) ,
                  bNTIRC = bNTIRC,
                  group  = "Group",
                  env = env1
)
p6 <- plot[[1]]
p6
```

#--系统发育信号

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\phylo_Micro\\phyloSignal_and_phySigplot.R")
phypath2 = paste(phypath,"/phyloSignal/",sep = "")
dir.create(phypath)

phyloSignal(ps = ps%>% filter_OTU_ps(200),
            group  = "Group",
            env = env1[,1:2],
            path = phypath2)

result = phySigPlot(ps = ps%>% filter_OTU_ps(200),
                    group  = "Group",env = env1[,1:2],
                    path = phypath2)
p2 = result[[1]]
p2
data = result[[2]]
head(data)
```

#--细菌-环境因子网络

```{R}
library(phyloseq)

Envnetplot<- paste("./16s_Env_network",sep = "")
dir.create(Envnetplot)
ps.merge <- ggClusterNet::merge16S_ITS(ps16s = ps,
                                       psITS = NULL,
                                       N16s = 200)
ps.merge
map =  phyloseq::sample_data(ps.merge)
head(map)
map$Group = "one"
phyloseq::sample_data(ps.merge) <- map
envRDA.s = vegan::decostand(env1,"hellinger")
data1 = envRDA.s %>% rownames_to_column("id")
Gru = data.frame(ID = colnames(env1),group = "env" )
head(Gru)
# library(sna)
# library(ggClusterNet)
# library(igraph)
result <- ggClusterNet::corBionetwork(ps = ps.merge,
                                      N = 0,
                                      r.threshold = 0.4, # 相关阈值
                                      p.threshold = 0.05,
                                      big = T,
                                      group = "Group",
                                      env = data1, # 环境指标表格
                                      envGroup = Gru,# 环境因子分组文件表格
                                      # layout = "fruchtermanreingold",
                                      path = Envnetplot,# 结果文件存储路径
                                      fill = "Phylum", # 出图点填充颜色用什么值
                                      size = "igraph.degree", # 出图点大小用什么数据
                                      scale = TRUE, # 是否要进行相对丰度标准化
                                      bio = TRUE, # 是否做二分网络
                                      zipi = F, # 是否计算ZIPI
                                      step = 100, # 随机网络抽样的次数
                                      width = 18,
                                      label = TRUE,
                                      height = 10
)
p = result[[1]]
p
data = result[[2]]
```

#-Tax4Fun2功能预测

```{R}
funcpath = paste("./Tax4Fun2/",sep = "")
dir.create(funcpath)

path_to_reference_data = "C:/public/Tax4Fun2/Tax4Fun2_ReferenceData_v2"
otudir = funcpath
#加载
library(Tax4Fun2)
#物种注释
#指定 OTU 代表序列、Tax4Fun2 库的位置、参考数据库版本、序列比对（blastn）线程数等
runRefBlast(path_to_otus = './data/otus2.fa', 
            path_to_reference_data = path_to_reference_data, 
            path_to_temp_folder = otudir, database_mode = 'Ref100NR', 
            use_force = TRUE, num_threads = 4)


#预测群落功能
#指定 OTU 丰度表、Tax4Fun2 库的位置、参考数据库版本、上步的物种注释结果路径等
makeFunctionalPrediction(path_to_otu_table = './data/otutab.txt',
                         path_to_reference_data = path_to_reference_data, 
                         path_to_temp_folder = otudir, 
                         database_mode = 'Ref100NR', 
                         normalize_by_copy_number = TRUE,
                         min_identity_to_reference = 0.97, 
                         normalize_pathways = FALSE)
```

#FEAST功能预测

```{R}
# source("E:\\Shared_Folder\\Function_local\\R_function\\Liu_project\\amplicon-master\\R\\开发花絮\\FEAST-master\\FEAST_src\\src.R")
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\FEAST.R",encoding = "UTF-8")

sample_data(ps)

result = FEAST(ps = ps,
               group = "Group",
               sinkG = "WT",
               sourceG = c("OE","KO"),
               path = "E:/Shared_Folder/Function_local/R_function/micro/" # 注意按照自己设定的路径进行修改
)

# result
p <- Plot_FEAST(data = result)
p
p2 = MuiPlot_FEAST(data = result)
p2
```

#-示例十三:微生物可视化#---------

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro/alpha-diversity.R")
index = c("Shannon","Inv_Simpson","Pielou_evenness","Simpson_evenness" ,"Richness" ,"Chao1","ACE" )
alp = alpha(ps = ps,inde="Shannon",group = "Group",Plot = TRUE )
index= alp
sel = c(match("Inv_Simpson",colnames(index)),
        match("Pielou_evenness",colnames(index)),
        match("Simpson_evenness",colnames(index)),
        match("Richness",colnames(index)),
        match("Chao1",colnames(index)),
        match("ACE",colnames(index)),
        match("Shannon",colnames(index))
        
)
n = length(sel) + 3
data = cbind(data.frame(ID = 1:length(index$Group),group = index$Group),index[sel])
head(data)
result = EasyStat::MuiKwWlx2(data = data,num = c(3:(n -1)))

result1 = EasyStat::FacetMuiPlotresultBox(data = data,num = c(3:(n -1)),
                                          result = result,
                                          sig_show ="abc",ncol = 3 )
p1_1 = result1[[1]] + 
  ggplot2::guides(fill = guide_legend(title = NULL)) 
p1_1
```

#-alpha稀释曲线

```{R}
rare <- mean(phyloseq::sample_sums(ps))/10
source("E:\\Shared_Folder\\Function_local\\R_function\\micro\\alpha_rare_all.R",encoding = "utf-8")
result = alpha_rare_all(ps = ps, group = "Group",
                        method = "Richness",
                        start = 100, step = rare)
p2_1 <- result[[1]] +
  guides(fill = guide_legend(title = NULL))
p2_1

result[[4]]
```

#beta排序分析

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro/BetaDiv.R")
source("E:\\Shared_Folder\\Function_local\\R_function\\micro/MicroTest.R")
source("E:\\Shared_Folder\\Function_local\\R_function\\micro/pairMicroTest.R")
result = BetaDiv(ps = ps, group = "Group", dist = "bray",
                method = "PCoA", Micromet = "anosim", 
                pvalue.cutoff = 0.05,
                pair = T)
result[[1]] 
```

#三元图

```{R}
ps_rela = phyloseq::transform_sample_counts(ps,
                                            function(x) x / sum(x) );ps_rela 
otu = ggClusterNet::vegan_otu(ps_rela) %>% as.data.frame()
#数据分组
iris.split <- split(otu,as.factor(as.factor(phyloseq::sample_data(ps)$Group)))
#数据分组计算平均值
iris.apply <- lapply(iris.split,function(x)colSums(x[]))
# 组合结果
iris.combine <- do.call(rbind,iris.apply)
ven2 = t(iris.combine) %>% as.data.frame()

head(ven2)
A <- combn(colnames(ven2),3)
ven2$mean = rowMeans(ven2)
tax = ggClusterNet::vegan_tax(ps)
otutax = cbind(ven2,tax)
head(otutax)
otutax$Phylum[otutax$Phylum == ""] = "Unknown"
i= 1
x = A[1,i]
y = A[2,i]
z = A[3,i]
p <- ggtern::ggtern(data=otutax,aes_string(x = x,y=y,z=z,color = "Phylum",size ="mean" ))+geom_point() + theme_void()
p
```

#-ggtree

```{R}
library(ggtreeExtra)
library(ggtree)

tax = ps %>% vegan_tax() %>%
  as.data.frame()
head(tax)
tax = remove_rankID(tax) %>%as.matrix()
tax[is.na(tax)] = "Unknown"
tax[tax == " "] = "Unknown"
tax_table(ps) = as.matrix(tax)

alltax = ps %>%
  ggClusterNet::filter_OTU_ps(150) %>%
  ggClusterNet::vegan_tax() %>%
  as.data.frame()
alltax$OTU = row.names(alltax)
head(alltax)
trda <- MicrobiotaProcess::convert_to_treedata(alltax)
p0 <- ggtree::ggtree(trda, layout="circular",
                     size=0.2, xlim=c(30,NA)) +
  geom_tippoint(color = "blue")
p0
```

#-------物种组成展示

```{R}
library(tidyverse)
detach("package:Hmisc")
source("E:\\Shared_Folder\\Function_local\\R_function\\micro/barMainplot.R")
result = barMainplot(ps = ps,
                     j = "Phylum",
                     label = FALSE,
                     sd = FALSE,
                     Top = 10)
p4_1 <- result[[1]] + 
  scale_fill_hue()
p4_1
p4_2  <- result[[3]] + 
  scale_fill_hue()
p4_2
```

# ggplot升级版本韦恩图和Upset

```{R}
source("E:\\Shared_Folder\\Function_local\\R_function\\micro/Ven.Upset.gg.R")
library(ggVennDiagram)
res = Ven.Upset(ps =  ps,
                group = "Group",
                N = 0.5,
                size = 3)

p1 = res[[1]]
p1
p2 = res[[2]]
p2
```

#--和弦图

```{R}
ps_rela = phyloseq::transform_sample_counts(ps, function(x) x / sum(x) );ps_rela 
ps_P <- ps_rela %>%
  ggClusterNet::tax_glom_wt( rank = "Phylum") 
ps_P
otu_P = as.data.frame((ggClusterNet::vegan_otu(ps_P)))
head(otu_P)
tax_P = as.data.frame(ggClusterNet::vegan_tax(ps_P))

sub_design <- as.data.frame(phyloseq::sample_data(ps_P))
count2 =   otu_P
#数据分组
iris.split <- split(count2,as.factor(sub_design$Group))
#数据分组计算平均值
iris.apply <- lapply(iris.split,function(x)colSums(x[]))
# 组合结果
iris.combine <- do.call(rbind,iris.apply)
ven2 = t(iris.combine)
# head(ven2)
lev = "Phylum"

Taxonomies <- ps %>%
  ggClusterNet::tax_glom_wt(rank = "Phylum") %>% 
  phyloseq::transform_sample_counts(function(x) {x/sum(x)} )%>% 
  phyloseq::psmelt() %>%
  #filter(Abundance > 0.05) %>%
  dplyr::arrange( Phylum)
iris_groups<- dplyr::group_by(Taxonomies, Phylum)
ps0_sum <- dplyr::summarise(iris_groups, mean(Abundance), sd(Abundance))
ps0_sum[is.na(ps0_sum)] <- 0
head(ps0_sum)
colnames(ps0_sum) = c("ID","mean","sd")


ps0_sum <- dplyr::arrange(ps0_sum,desc(mean))
ps0_sum$mean <- ps0_sum$mean *100
ps0_sum <- as.data.frame(ps0_sum)
head(ps0_sum)
top_P = ps0_sum$ID[1:Top];top_P

### 开始进一步合并过滤
otu_P = as.data.frame(t(otu_P))
otu_tax = merge(ven2,tax_P,by = "row.names",all = F)
dim(otu_tax)
otu_tax[,lev] = as.character(otu_tax[,lev])
otu_tax[,lev][is.na(otu_tax[,lev])] = "others"

i = 1
for (i in 1:nrow(otu_tax)) {
  if(otu_tax[,lev] [i] %in% top_P){otu_tax[,lev] [i] = otu_tax[,lev] [i]}
  
  else if(!otu_tax[,lev] [i] %in% top_P){otu_tax[,lev] [i] = "others"}
  
}

otu_tax[,lev] = as.factor(otu_tax[,lev])
head(otu_tax)

otu_mean = otu_tax[as.character(unique(sub_design$Group))]
head(otu_mean)
row.names(otu_mean) = row.names(otu_tax)
iris.split <- split(otu_mean,as.factor(otu_tax[,lev]))
#数据分组计算平均值
iris.apply <- lapply(iris.split,function(x)colSums(x[]))
# 组合结果
iris.combine <- do.call(rbind,iris.apply)
mer_otu_mean = t(iris.combine)

head(mer_otu_mean )


# mer_otu_mean = t(mer_otu_mean)


# library(statnet)
# library(circlize)
# library(RColorBrewer)#调色板调用包
mi_sam = RColorBrewer::brewer.pal(9,"Set1")
mi_tax = colorRampPalette(RColorBrewer::brewer.pal(9,"Set3"))(length(row.names(mer_otu_mean)))
# library("scales")
# show_col(mi_sam )
# show_col(mi_tax)
# circlize::CELL_META

grid.col = NULL
#这里设置样品颜色
grid.col[as.character(unique(sub_design$Group))] = mi_sam
#设置群落中物种水平颜色
# grid.col[colnames(mer_otu_mean)] = mi_tax
grid.col[row.names(mer_otu_mean)] = mi_tax


#gap.degree修改间隔，不同小块之间的间隔
circlize::circos.par(gap.degree = c(rep(2, nrow(mer_otu_mean)-1), 10, rep(2, ncol(mer_otu_mean)-1), 10),
                     start.degree = 180)
circlize::chordDiagram(mer_otu_mean,
                       directional = F,
                       diffHeight = 0.06,
                       grid.col = grid.col, 
                       reduce = 0,
                       transparency = 0.5, 
                       annotationTrack =c("grid", "axis"),
                       preAllocateTracks = 2
)

circlize::circos.track(track.index = 1, panel.fun = function(x, y) {
  circlize::circos.text(circlize::CELL_META$xcenter, circlize::CELL_META$ylim[1], circlize::CELL_META$sector.index,
                        facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))}, bg.border = NA)# here set bg.border to NA is important
circlize::circos.clear()
dev.off()
# grid.col = NULL
# #这里设置样品颜色
# grid.col[as.character(unique(sub_design$Group))] = mi_sam
# #设置群落中物种水平颜色
# # grid.col[colnames(mer_otu_mean)] = mi_tax
# grid.col[row.names(mer_otu_mean)] = mi_tax
# 
# #gap.degree修改间隔，不同小块之间的间隔
# circlize::circos.par(gap.degree = c(rep(2, nrow(mer_otu_mean)-1), 10, rep(2, ncol(mer_otu_mean)-1), 10),
#                      start.degree = 180)
# circlize::chordDiagram(mer_otu_mean,directional = F,
#                        reduce = 0,
#                        diffHeight = 0.06,grid.col = grid.col, transparency = 0.5, annotationTrack =c("grid", "axis"),
#                        preAllocateTracks = 2
# )
# 
# circlize::circos.track(track.index = 1, panel.fun = function(x, y) {
#   circlize::circos.text(circlize::CELL_META$xcenter, circlize::CELL_META$ylim[1], circlize::CELL_META$sector.index,
#                         facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))}, bg.border = NA) # here set bg.border to NA is important
# circlize::circos.clear()
# dev.off()
```

#--patchwork拼图

```{R}
library(ggplot2)
library(patchwork)
p1 <- ggplot(mtcars) + 
  geom_point(aes(mpg, disp)) + 
  ggtitle('Plot 1')
p2 <- ggplot(mtcars) + 
  geom_boxplot(aes(gear, disp, group = gear)) + 
  ggtitle('Plot 2')
p3 <- ggplot(mtcars) + 
  geom_point(aes(hp, wt, colour = mpg)) + 
  ggtitle('Plot 3')

p1+p2+p3
```

